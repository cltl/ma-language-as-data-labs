{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Obtaining statistics for your text collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright, Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this assignment you can earn 10 points for your final grade. What do you need to do?\n",
    "\n",
    "<ol>\n",
    "    <li> [*2 points*]: Collect 100 texts from two different media on a topic of your choice but not *vaccination*. You can choose your medium: Google news, tweets, Techcrunch, etc. Make sure you have 50 documents from each medium, e.g. 50 news articles and 50 tweets.\n",
    "    <li> [*6 points*]: Apply spaCy NLP to each text and obtain the following statistics for each corpus:\n",
    "        <ul>\n",
    "            <li> Total number of tokens\n",
    "            <li> Total number of lemmas\n",
    "            <li> Total number of sentences\n",
    "            <li> Average token length\n",
    "            <li> Average nr. tokens per sentence\n",
    "            <li> Total number of nouns, verbs, adjectives, adverbs, etc., covering all parts-of-speeches in the texts\n",
    "            <li> Proportion of nouns, verbs, adjectives, etc. given the total number of words\n",
    "        </ul>\n",
    "     <li> [*1 point*]: Output the statistics in a CSV file such that you can compare the statistics across the two corpora obtained from different media\n",
    "     <li> [*1 point*]: What can you tell about the differences? Is this what you expected and can you explain why?\n",
    "</ol>\n",
    "\n",
    "The next tables shows how the output should look like:\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<th></th>\n",
    "<th>DataSet1</th>\n",
    "<th>DataSet2</th>\n",
    "</tr>\n",
    "   <tr> <td>Total nr. of tokens</td><td>500</td> <td>500</td></tr>\n",
    "   <tr> <td>Total nr. of lemmas</td><td>10</td> <td>500</td> </tr>\n",
    "   <tr> <td>Total nr. of sentences</td><td>10</td> <td>500</td> </tr>\n",
    "   <tr> <td>Average token lengths</td><td>10</td> <td>500</td> </tr>\n",
    "   <tr> <td>Average nr of tokens per sentences</td><td>10</td> <td>500</td> </tr>\n",
    "   <tr> <td>Total nr. of nouns</td><td>10</td> <td>500</td> </tr>\n",
    "   <tr> <td>Total nr. of verbs</td><td>10</td> <td>500</td> </tr>\n",
    "   <tr> <td>Total nr. of adjectives</td><td>10</td> <td>500</td> </tr>\n",
    "   <tr> <td>Total nr. of adverbs</td><td>10</td> <td>500</td> </tr>\n",
    "   <tr> <td>Total nr. of pronouns</td><td>10</td> <td>500</td> </tr>\n",
    "   <tr> <td>Total nr. of proper names</td><td>10</td> <td>500</td> </tr>\n",
    "   <tr> <td>Total nr. of prepositions</td><td>10</td> <td>500</td> </tr>\n",
    "   <tr> <td>Total nr. of determiners</td><td>10</td> <td>500</td> </tr>\n",
    "   <tr> <td>Total nr. of etc...</td><td>10</td> <td>500</td> </tr>\n",
    "   <tr> <td>Proportion of nouns</td><td>10%</td> <td>10%</td> </tr>\n",
    "   <tr> <td>Proportion of verbs</td><td>10%</td> <td>10%</td> </tr>\n",
    "   <tr> <td>Proportion of adjectives</td><td>10%</td> <td>10%</td> </tr>\n",
    "   <tr> <td>Proportion of adverbs</td><td>10%</td> <td>10%</td> </tr>\n",
    "   <tr> <td>Proportion of pronouns</td><td>10%</td> <td>10%</td> </tr>\n",
    "   <tr> <td>Proportion of proper names</td><td>10%</td> <td>10%</td> </tr>\n",
    "   <tr> <td>Proportion of prepositions</td><td>10%</td> <td>10%</td> </tr>\n",
    "   <tr> <td>Proportion of determiners</td><td>10%</td> <td>10%</td> </tr>\n",
    "   <tr> <td>Proportion of etc...</td><td>10%</td> <td>10%</td> </tr></table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Collect 100 texts from two media [2 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here comes you code to call the API for two media using the query words of your choice\n",
    "\n",
    "# [YOUR CODE GOES HERE]\n",
    "\n",
    "# You should store the results in two separate folders so that you can read the text later in this assignment \n",
    "# and in future assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Apply spaCy to obtain the statistics for each text collection [6 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to have global counters to answer these questions for two collections (corpora)\n",
    "\n",
    "# Total number of tokens\n",
    "# Total number of lemmas\n",
    "# Total number of sentences\n",
    "# Total number of nouns, verbs, adjectives, adverbs, etc., covering all parts-of-speeches in the texts\n",
    "# Average token length\n",
    "# Average nr. tokens per sentence\n",
    "# Proportion of nouns, verbs, adjectives, etc. given the total number of words\n",
    "\n",
    "nrSentencesCorpus1=0\n",
    "nrTokensCorpus1=0\n",
    "nrLemmasCorpus1=0\n",
    "posCountDictionaryCorpus1={}\n",
    "posProportionDictionaryCorpus1={}\n",
    "averageTokenLengthCorpus1=0\n",
    "averageTokensPerSentenceCorpus1=0\n",
    "\n",
    "nrSentencesCorpus2=0\n",
    "nrTokensCorpus2=0\n",
    "nrLemmasCorpus2=0\n",
    "posCountDictionaryCorpus2={}\n",
    "posProportionDictionaryCorpus2={}\n",
    "averageTokenLengthCorpus2=0\n",
    "averageTokensPerSentenceCorpus2=0\n",
    "\n",
    "\n",
    "# You need to load all the files from a subcorpus one by one\n",
    "\n",
    "# [YOUR CODE GOES HERE]\n",
    "\n",
    "# You need to process each file using spaCy\n",
    "\n",
    "# [YOUR CODE GOES HERE]\n",
    "\n",
    "# You need to iterate over the spaCy result and create the dictionaries and the counts\n",
    "# that are required\n",
    "\n",
    "# [YOUR CODE GOES HERE]\n",
    "\n",
    "# make sure you can derive the right counts per document and per collection\n",
    "\n",
    "# [YOUR CODE GOES HERE]\n",
    "\n",
    "# You need to do this twice, once for each collection and keep the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Output the statistics to a CSV file for contrastive analysis [1 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you managed to store all the data in global variables, you now should be able to output these\n",
    "# as Strings and Integers following a CSV format.\n",
    "\n",
    "# make sire you have the counts for each collection in different columns sharing the rows\n",
    "\n",
    "# [YOUR CODE GOES HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Reflect on the comparison [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ YOUR ANALYSIS OF THE STATISTICS COMES HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
