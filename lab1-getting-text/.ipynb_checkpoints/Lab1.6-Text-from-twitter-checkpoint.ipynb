{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1.3: Twitter as a source of text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to query Twitter streams using the package `tweepy`: https://github.com/tweepy/tweepy\n",
    "Some documentation can be found at: https://github.com/tweepy/tweepy/tree/master/docs\n",
    "\n",
    "Tweepy allows you to access Twitter using credentials and returns a so-called Cursor object. From the Cursor object, you can access the twitter data in e.g. JSON format. Documentation on the Twitter data objects can be found here:\n",
    "\n",
    "https://developer.twitter.com/en/docs\n",
    "\n",
    "\n",
    "Instructions on how to install Tweepy, get credentials and use the API can be found here:\n",
    "\n",
    "http://socialmedia-class.org/twittertutorial.html\n",
    "\n",
    "The notebook below is partially based on this tutorial. Credits: Wei Xu\n",
    "\n",
    "Make sure you installed the package and obtained the Twitter credentials before your start using the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up a your twitter credentials to use the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next code, we are importing a `json` package and the `tweepy` package. Next, we first set up tweepy with the authenticaton credentials so that we can make a connection. Consult the documentation on how to get your credentials: \n",
    "\n",
    "https://developer.twitter.com/en/docs\n",
    "\n",
    "If you have an account and can login on the developer site of twitter, you will see a Apps in the top-right corner. You can Add an new app and are asked for an account. Choose the student account to proceed. You need to fill in some information about the country and usage. Use the following text block throughout and answer the last two questions with no:\n",
    "\n",
    "`teaching text mining in the vu university master program of the faculty of humanities. Analyse tweets for extracting data and information and obtaining statistics on language use. I am a student in this course.\n",
    "`\n",
    "Confirm and agree with the license conditions. Confirm the email and obtain the credentials. Now you can create a new app. Fill in a bogus name (but unique), URL and description and confirm. Going through the last confirmations you obtain the app and you can get the credentials.\n",
    "\n",
    "If you fail to create your credentials, approach me to obtain the ones I defined for the course.\n",
    "\n",
    "Using the credentials, we will call the `tweepy.API` function to create an api object. We show how you can get the results through a `Cursor` function of tweepy, in which you need to set a number of variables. We use the search api to pass a keyword as a query and limit the results to a number of tweets, number of pages, excluding retweets and setting a period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary package to process data in JSON format\n",
    "try:\n",
    "    import json\n",
    "except ImportError:\n",
    "    import simplejson as json\n",
    "\n",
    "# Import the tweepy library\n",
    "import tweepy\n",
    "\n",
    "# Variables that contains the user credentials to access Twitter API \n",
    "#ACCESS_TOKEN = 'YOUR ACCESS TOKEN\"'\n",
    "#ACCESS_SECRET = 'YOUR ACCESS TOKEN SECRET'\n",
    "#CONSUMER_KEY = 'YOUR API KEY'\n",
    "#CONSUMER_SECRET = 'ENTER YOUR API SECRET'\n",
    "\n",
    "# Variables that contains the user credentials to access Twitter API \n",
    "ACCESS_TOKEN = ''\n",
    "ACCESS_SECRET = ''\n",
    "CONSUMER_KEY = ''\n",
    "CONSUMER_SECRET = ''\n",
    "\n",
    "# Setup tweepy to authenticate with Twitter credentials:\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tweepy package created an authentication object 'auth' that we can now use to create access to the API by creating an API object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the api to connect to twitter with your credentials\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True)\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# wait_on_rate_limit= True;  will make the api to automatically wait for rate limits to replenish\n",
    "# wait_on_rate_limit_notify= Ture;  will make the api  to print a notification when Tweepyis waiting for rate limits to replenish\n",
    "#---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using the Twitter API to make queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As twitter is a stream, we define a number of variables to constraint the search. We also define a range of keywords as BOOLEAN combinations using OR and AND."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# we now predefine some variables to restrict the twitter stream\n",
    "\n",
    "#set two date variables for date range\n",
    "start_date = '2018-10-01'\n",
    "end_date = '2018-10-31'\n",
    "\n",
    "#we define the nr_tweets we want to return \n",
    "nr_tweets=10\n",
    "\n",
    "#finally, we define a query. Note that we can mix hash tags with words and use boolean operators OR and AND\n",
    "keywords='#autism AND vaccines OR medicine AND children'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the parameters to tune our search. Tweepy provides a 'Cursor' function to call the search API with our parameters. It returns the results as pages through which we can iterate to obtain as JSON results. From this JSON result, we can get all kinds of data elements for each twqeet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\n",
      "User:andrewmorrisuk \n",
      " Tweet:RT @and_kell: Do you know vaccines do indeed trigger an encephalopathy in vulnerable children. Later diagnosed as #autism\n",
      "\n",
      "Doctors who push…\n",
      "\n",
      "1\n",
      "User:terriblewis1 \n",
      " Tweet:RT @and_kell: Do you know vaccines do indeed trigger an encephalopathy in vulnerable children. Later diagnosed as #autism\n",
      "\n",
      "Doctors who push…\n",
      "\n",
      "2\n",
      "User:through_purity \n",
      " Tweet:RT @i4dzn: @FOX5Atlanta And, could just be the reason that children who were born seemingly okay later developed #Autism, not the #vaccines…\n",
      "\n",
      "3\n",
      "User:i4dzn \n",
      " Tweet:@kwilks1120 No. Most diagnosed w #autism are born with it. There’s autism in kids who didn’t have #vaccines. Most d… https://t.co/RIIHqR5iZj\n",
      "\n",
      "4\n",
      "User:i4dzn \n",
      " Tweet:@nypost And, could just be the reason that children who were born seemingly okay later developed #Autism, not the… https://t.co/CdzM5b7Qwp\n",
      "\n",
      "5\n",
      "User:i4dzn \n",
      " Tweet:@ABC7Amarillo And, could just be the reason that children who were born seemingly okay later developed #Autism, not… https://t.co/wwXMHiW2FA\n",
      "\n",
      "6\n",
      "User:i4dzn \n",
      " Tweet:@FOX5Atlanta And, could just be the reason that children who were born seemingly okay later developed #Autism, not… https://t.co/AvX2WSrnMC\n",
      "\n",
      "7\n",
      "User:LeiSurz073 \n",
      " Tweet:@Rosewind2007 This does need to be said:\n",
      "Lots of people have vaccine injured children. \n",
      "They have a child they wish… https://t.co/MxnEX05iTV\n",
      "\n",
      "8\n",
      "User:grhluna24 \n",
      " Tweet:RT @BigDonQTrump: Fetus or child. No matter the opinion, the DNA is HUMAN. Vaccines containing human DNA create a biologic neurological eff…\n",
      "\n",
      "9\n",
      "User:andrewmorrisuk \n",
      " Tweet:RT @BigDonQTrump: Fetus or child. No matter the opinion, the DNA is HUMAN. Vaccines containing human DNA create a biologic neurological eff…\n",
      "\n",
      "0\n",
      "User:NurseDynamite \n",
      " Tweet:RT @BigDonQTrump: Fetus or child. No matter the opinion, the DNA is HUMAN. Vaccines containing human DNA create a biologic neurological eff…\n",
      "\n",
      "1\n",
      "User:BigDonQTrump \n",
      " Tweet:Fetus or child. No matter the opinion, the DNA is HUMAN. Vaccines containing human DNA create a biologic neurologic… https://t.co/aXML9TvJX2\n",
      "\n",
      "2\n",
      "User:andrewmorrisuk \n",
      " Tweet:RT @and_kell: Do you know vaccines do indeed trigger an encephalopathy in vulnerable children. Later diagnosed as #autism\n",
      "\n",
      "Doctors who push…\n",
      "\n",
      "3\n",
      "User:KatesDailyBread \n",
      " Tweet:RT @and_kell: Do you know vaccines do indeed trigger an encephalopathy in vulnerable children. Later diagnosed as #autism\n",
      "\n",
      "Doctors who push…\n",
      "\n",
      "4\n",
      "User:Twitlertwit \n",
      " Tweet:RT @ViraBurnayeva: #STUDY: #Mercury Toxic Encephalopathies w/ Symptoms of #Autism\n",
      "\n",
      "https://t.co/l8qZjaCXbG\n",
      "\n",
      "\"There was a significant dose-r…\n",
      "\n",
      "5\n",
      "User:nicolettamall \n",
      " Tweet:RT @Vaccinologist: Danish researchers studied 1.2 million children from 1991 to 2010 looking to see if there is an association between #MMR…\n",
      "\n",
      "6\n",
      "User:sarhahubbard619 \n",
      " Tweet:RT @ViraBurnayeva: #STUDY: #Mercury Toxic Encephalopathies w/ Symptoms of #Autism\n",
      "\n",
      "https://t.co/l8qZjaCXbG\n",
      "\n",
      "\"There was a significant dose-r…\n",
      "\n",
      "7\n",
      "User:melissactweets \n",
      " Tweet:RT @ViraBurnayeva: #STUDY: #Mercury Toxic Encephalopathies w/ Symptoms of #Autism\n",
      "\n",
      "https://t.co/l8qZjaCXbG\n",
      "\n",
      "\"There was a significant dose-r…\n",
      "\n",
      "8\n",
      "User:thatslifefolks1 \n",
      " Tweet:@TRJForBloggers #School #nurse crisis reaching extreme proportions\n",
      "#anxiety\n",
      "https://t.co/nFhXb34jWN\n",
      "#children… https://t.co/LN8ohNMtO4\n",
      "\n",
      "9\n",
      "User:patriot7842 \n",
      " Tweet:RT @ViraBurnayeva: #STUDY: #Mercury Toxic Encephalopathies w/ Symptoms of #Autism\n",
      "\n",
      "https://t.co/l8qZjaCXbG\n",
      "\n",
      "\"There was a significant dose-r…\n",
      "\n",
      "0\n",
      "User:BoonieKane \n",
      " Tweet:RT @ViraBurnayeva: #STUDY: #Mercury Toxic Encephalopathies w/ Symptoms of #Autism\n",
      "\n",
      "https://t.co/l8qZjaCXbG\n",
      "\n",
      "\"There was a significant dose-r…\n",
      "\n",
      "1\n",
      "User:GraceHealz \n",
      " Tweet:RT @ViraBurnayeva: #STUDY: #Mercury Toxic Encephalopathies w/ Symptoms of #Autism\n",
      "\n",
      "https://t.co/l8qZjaCXbG\n",
      "\n",
      "\"There was a significant dose-r…\n",
      "\n",
      "2\n",
      "User:grhluna24 \n",
      " Tweet:RT @ViraBurnayeva: #STUDY: #Mercury Toxic Encephalopathies w/ Symptoms of #Autism\n",
      "\n",
      "https://t.co/l8qZjaCXbG\n",
      "\n",
      "\"There was a significant dose-r…\n",
      "\n",
      "3\n",
      "User:CandyCaulton \n",
      " Tweet:RT @ViraBurnayeva: #STUDY: #Mercury Toxic Encephalopathies w/ Symptoms of #Autism\n",
      "\n",
      "https://t.co/l8qZjaCXbG\n",
      "\n",
      "\"There was a significant dose-r…\n",
      "\n",
      "4\n",
      "User:cruzcorba \n",
      " Tweet:RT @Vaccinologist: Danish researchers studied 1.2 million children from 1991 to 2010 looking to see if there is an association between #MMR…\n",
      "\n",
      "5\n",
      "User:WilliamRCamero1 \n",
      " Tweet:RT @ViraBurnayeva: #STUDY: #Mercury Toxic Encephalopathies w/ Symptoms of #Autism\n",
      "\n",
      "https://t.co/l8qZjaCXbG\n",
      "\n",
      "\"There was a significant dose-r…\n",
      "\n",
      "6\n",
      "User:freshfacesuk \n",
      " Tweet:RT @ViraBurnayeva: #STUDY: #Mercury Toxic Encephalopathies w/ Symptoms of #Autism\n",
      "\n",
      "https://t.co/l8qZjaCXbG\n",
      "\n",
      "\"There was a significant dose-r…\n",
      "\n",
      "7\n",
      "User:ViraBurnayeva \n",
      " Tweet:#STUDY: #Mercury Toxic Encephalopathies w/ Symptoms of #Autism\n",
      "\n",
      "https://t.co/l8qZjaCXbG\n",
      "\n",
      "\"There was a significant d… https://t.co/ECbWT6S7Am\n",
      "\n",
      "8\n",
      "User:freedomgirl2011 \n",
      " Tweet:Corporations will make money off your brain damaged child,one in 38 children in United States are diagnosed with… https://t.co/ZT0JOjqTF2\n",
      "\n",
      "9\n",
      "User:andrewmorrisuk \n",
      " Tweet:RT @sallyKP: From 2011... listen.\n",
      "\n",
      "Very sad for all of the families who have been advocating for 20 years now.\n",
      "\n",
      "What would happen if the US…\n",
      "\n",
      "0\n",
      "User:anhisu7 \n",
      " Tweet:RT @sallyKP: From 2011... listen.\n",
      "\n",
      "Very sad for all of the families who have been advocating for 20 years now.\n",
      "\n",
      "What would happen if the US…\n",
      "\n",
      "1\n",
      "User:WarriorWifeMom \n",
      " Tweet:RT @sallyKP: From 2011... listen.\n",
      "\n",
      "Very sad for all of the families who have been advocating for 20 years now.\n",
      "\n",
      "What would happen if the US…\n",
      "\n",
      "4\n",
      "User:andrewmorrisuk \n",
      " Tweet:RT @BioscienceNB: #educateyourself\n",
      "10 years and over 600,000 children.\n",
      "\n",
      "As promised, here is another link to the most recent study conducte…\n",
      "\n",
      "5\n",
      "User:BioscienceNB \n",
      " Tweet:#educateyourself\n",
      "10 years and over 600,000 children.\n",
      "\n",
      "As promised, here is another link to the most recent study co… https://t.co/Vkc5EWVnyy\n",
      "\n",
      "6\n",
      "User:JMONEILL1975 \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "7\n",
      "User:tow4u44 \n",
      " Tweet:RT @and_kell: Do you know vaccines do indeed trigger an encephalopathy in vulnerable children. Later diagnosed as #autism\n",
      "\n",
      "Doctors who push…\n",
      "\n",
      "8\n",
      "User:lizz_dawn \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "9\n",
      "User:JONJONLIVES1 \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "0\n",
      "User:constantin_t \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "1\n",
      "User:LDSLibertarian1 \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "2\n",
      "User:mal0406 \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "3\n",
      "User:bobglomorrison \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "4\n",
      "User:shekinah1313 \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "5\n",
      "User:DrKND \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "6\n",
      "User:littlorangefish \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "7\n",
      "User:terriblewis1 \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "8\n",
      "User:BoggyLuuuu \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "9\n",
      "User:andrewmorrisuk \n",
      " Tweet:RT @and_kell: Do you know vaccines do indeed trigger an encephalopathy in vulnerable children. Later diagnosed as #autism\n",
      "\n",
      "Doctors who push…\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Twitter API development use pagination for Iterating through timelines, user lists, direct messages, etc. \n",
    "# To help make pagination easier and Tweepy has the Cursor object.\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "for page in tweepy.Cursor(api.search, q=keywords,\n",
    "                     count=nr_tweets, include_rts=False, since=start_date, till=end_date).pages(5):\n",
    "    for index, status in enumerate(page):\n",
    "        \n",
    "        ## we get a json object from the result\n",
    "        json_result = status._json\n",
    "        \n",
    "        ## check whether the tweet is in english or skip to the next tweet\n",
    "        if json_result['lang'] != 'en':\n",
    "            continue\n",
    "\n",
    "        text=json_result['text']\n",
    "        name=json_result['user']['screen_name']\n",
    "        print(\"\\n\"+str(index)+\"\\nUser:\"+name, \"\\n\", \"Tweet:\" + text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here 5 pages which each 10 tweets, where we print the user name and the text. As you can see, the tweets contains all kinds of non-textual elements as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Saving the JSON structures to a JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of printing the tweet text and screen name to the screen, we also directly dump the JSON result to a file.\n",
    "We show this next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a file path to store the results as CSV. Make sure the folder 'twitter_search_results' exists \n",
    "# or that you specify another path to an existing location. The 'twitter_results_vaccination.csv' file will be created in that location.\n",
    "jsonFilePath='twitter_search_results/twitter_results_vaccination.json'\n",
    "\n",
    "json_all_results={}\n",
    "\n",
    "for page in tweepy.Cursor(api.search, q=keywords,\n",
    "                     count=nr_tweets, include_rts=False, since=start_date, till=end_date).pages(5):\n",
    "    for index, status in enumerate(page):\n",
    "        \n",
    "        ## we get a json object from the result\n",
    "        json_result = status._json\n",
    "        tweet_id = json_result['id']\n",
    "        json_all_results[tweet_id]=json_result\n",
    "\n",
    "## we open the result file for saving the JSON, 'fp' stands for file pointer\n",
    "with open(jsonFilePath, 'w') as fp:\n",
    "  json.dump(json_all_results, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now open the file `jsonFilePath` in a plain text editor and inspect the structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Saving a selection of data elements to a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The JSON output contains all kinds of meta data in addition to the tweet itself. We are going to show how you can get these and save the result as a CSV output file. We assume the above imports and credentials and re-use the API we defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain the relevant information, you need to know the JSON structure of the output. Please consult the Twitter documentation to understand the structure.\n",
    "\n",
    "https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/intro-to-tweet-json\n",
    "\n",
    "We are going to define a number of columns for a CSV file to store the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS = ['id', 'created_at', 'source', 'tweet_text', 'lang',\n",
    "'favorite_count', 'retweet_count', 'original_author', 'hashtags',\n",
    "'user_mentions', 'place', 'place_coord_boundaries']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code shows how we obtain the above data from the JSON structure and store it in a single CSV file. For illustration, we are going to use the same settings and API as before.\n",
    "\n",
    "To create the output as CSV data, we are going to use the Pandas package: https://pandas.pydata.org\n",
    "Please follow the instructions to install pandas locally:\n",
    "\n",
    "* `conda install pandas`\n",
    "* `python -m pip install --upgrade pandas`\n",
    "\n",
    "Consult the documentation to learn more about the functionalities. Here we are going to use it to convert our list of featurures for a tweet to a CSV format.\n",
    "\n",
    "We need to import `os` for writing to a file and `pandas` (after the install) for dealing with the data structure. Take your time to study the next bit of code so that you understand the individual steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#set two date variables for date range\n",
    "start_date = '2018-10-01'\n",
    "end_date = '2018-10-31'\n",
    "\n",
    "#we define the nr_tweets we want to return \n",
    "nr_tweets=10\n",
    "\n",
    "#finally, we define a query. Note that we can mix hash tags with words and use boolean operators OR and AND\n",
    "keywords='#autism AND vaccines OR medicine AND children'\n",
    "\n",
    "# We first define a data frame that we name 'all_tweets_dataframe' with pandas imported as 'pd' using the columns list that we defined before.\n",
    "# Basically, we tell pandas what data will be stored.\n",
    "all_tweets_dataframe = pd.DataFrame(columns=COLS)\n",
    "\n",
    "for page in tweepy.Cursor(api.search, q=keywords,\n",
    "                     count=nr_tweets, include_rts=False, since=start_date).pages(50):\n",
    "    # now we have the tweets, we are going to obtain the features from the json and store them in the right order for our data frame\n",
    "    for status in page:\n",
    "        ## new_entry is going to contain the data \n",
    "        new_entry = []\n",
    "        \n",
    "        ## we get a json object from the result\n",
    "        status = status._json\n",
    "        \n",
    "        ## check whether the tweet is in english or skip to the next tweet\n",
    "        if status['lang'] != 'en':\n",
    "            continue\n",
    "\n",
    "        text=status['text']\n",
    "        \n",
    "        #new entry append in the order of the data frame\n",
    "        new_entry += [status['id'], \n",
    "                      status['created_at'],\n",
    "                      status['source'], \n",
    "                      status['text'],\n",
    "                      status['lang'],\n",
    "                      status['favorite_count'], \n",
    "                      status['retweet_count']]\n",
    "\n",
    "        #to append original author of the tweet\n",
    "        new_entry.append(status['user']['screen_name'])\n",
    "\n",
    "        # hashtagas and mentiones are saved using comma separted\n",
    "        hashtags = \", \".join([hashtag_item['text'] for hashtag_item in status['entities']['hashtags']])\n",
    "        new_entry.append(hashtags)\n",
    "        mentions = \", \".join([mention['screen_name'] for mention in status['entities']['user_mentions']])\n",
    "        new_entry.append(mentions)\n",
    "\n",
    "        #get location of the tweet if possible\n",
    "        try:\n",
    "            location = status['user']['location']\n",
    "        except TypeError:\n",
    "            location = ''\n",
    "        new_entry.append(location)\n",
    "\n",
    "        try:\n",
    "            coordinates = [coord for loc in status['place']['bounding_box']['coordinates'] for coord in loc]\n",
    "        except TypeError:\n",
    "            coordinates = None\n",
    "        new_entry.append(coordinates)\n",
    "\n",
    "        # We now completed appending all the possible values for this tweet.\n",
    "        # We use the pandas framework imported as 'pd' to create a dataframe from the aggregated data in new_entry\n",
    "        # We need to provide the columns COLS to tell pandas what value belongs to what.\n",
    "        # Note that the data need to be aggregated in the same order as the names in COLS, otherwise values will get mixed up\n",
    "        single_tweet_dataframe = pd.DataFrame([new_entry], columns=COLS)\n",
    "        \n",
    "        # single_tweet_dataframe now contains the data for a single tweet\n",
    "        # next we add it to the data frame for all tweets 'all_tweets_dataframe'\n",
    "        # check the pandas documentation if you want to know what ignore_index=True does to the data aggregation\n",
    "        all_tweets_dataframe = all_tweets_dataframe.append(single_tweet_dataframe, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data frame basically is a table with columns and rows. We use the `shape` function to ask for the number of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58, 12)\n"
     ]
    }
   ],
   "source": [
    "print(all_tweets_dataframe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the *pandas* framework, we can now save it to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a file path to store the results as CSV. Make sure the folder 'twitter_search_results' exists \n",
    "# or that you specify another path to an existing location. The 'twitter_results_vaccination.csv' file will be created in that location.\n",
    "csvFilePath='twitter_search_results/twitter_results_vaccination.csv'\n",
    "\n",
    "# we now open the csvFile for appending our result\n",
    "csvFile = open(csvFilePath,\"w+\")       \n",
    "all_tweets_dataframe.to_csv(csvFile, columns=COLS, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
