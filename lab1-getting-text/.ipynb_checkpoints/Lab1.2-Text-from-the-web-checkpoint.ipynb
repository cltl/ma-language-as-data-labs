{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1.2: The web as a source of text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The WWW consists of web pages that are either created as static HTML or generated dynamically from databases or other formats.\n",
    "\n",
    "HTML stands for Hyper Text Markup Language. It basically tells the browser how to render a web page in a browser so that people can easily access the content.\n",
    "\n",
    "HTML contains more than just the content. It includes the instructions to the browser how to render it. It may also contain other data such as Java Script to run little programs, hyperlinks to other webpages, images, video's, or comments made by the people that created the page.\n",
    "\n",
    "In order to get the content from a web page, we need to separate the language from the instructions. For this we use the package *BeautifulSoup*.\n",
    "\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import re\n",
    "\n",
    "#Utility function to get the raw text from a web page. \n",
    "#It takes a URL string as input and returns the text.\n",
    "def url_to_string(url):\n",
    "    res = requests.get(url)\n",
    "    html = res.text\n",
    "    soup = BeautifulSoup(html, 'html5lib')\n",
    "    for script in soup([\"script\", \"style\", 'aside']):\n",
    "        script.extract()\n",
    "    return \" \".join(re.split(r'[\\n\\t]+', soup.get_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CLTL | the Computational Lexicology & Terminology Lab of Prof. Dr. Piek Vossen   CLTL the Computational Lexicology & Terminology Lab of Prof. Dr. Piek Vossen Menu Skip to content HomePeople Projects Future Projects The Reference Machine Theory of Identity, Reference and Perspective (TIRP) Discriminatory Micro Portraits Current projects Robot Leolani Weekend of Science 2018: Talking with Robots Leolani in Brno 2018 Weekend of Science 2017: Talking with Robots Understanding of Language by Machines Dutch Framenet Hybrid Intelligence SERPENS Word, Sense and Reference QuPiD2 HHuCap Reading between the lines VU University Research Fellow CLARIAH Visualizing Uncertainty and Perspectives Digital Humanities Open Dutch Wordnet Global WordNet Grid Global WordNet Association Previous projects NewsReader BiographyNet Language, Knowledge and People in Perspective CLIN26 Investigating Criminal Networks INclusive INsight Can we Handle the News (EYR4) OpeNER Mapping Notes and Nodes in Networks KYOTO Cornetto-LMF-RDF From sentiments and opinions in texts to positions of political parties Semantics of History TH@SIS DutchSemCor FLaReNet Cornetto DutchSemCor Pilotgrant StoreTelling Centres & Associations Global WordNet Association Dutch Terminology Service Centre Centre for Digital Humanities Amsterdam Teaching Human Language Technology ▷Track in 2-year Research Master Humanities Human Language Technology Program 2018-2019 Text Mining ▷Track in 1-year Master Linguistics Forensic Linguistics  ▷Track in 2-year Research Master Humanities Minor Digital Humanities Student Assistant Projects Enhancing Quality Assessment Using Perspective Detection Mining Stereotypes Modelling Perspectives in Philosophy Political Discourse in the news Mining Causal Graphs from Patient Records Medical Trust Networks Polemics Visualised Time will tell a different story Call for Student Assistants Student projects Text Mining Student projects Text Mining 2018 Student Projects Text Mining 2017 Student Projects Text Mining 2016 Thesis topics and Internships Internships Scholarships Meet & Greet companies & CLTL-students Meet & Greet December 13, 2019 Meet & Greet December 8, 2017 Publications Publications CLTL Publication Requirements Resources Corpora and Lexica Demos Open Source Dutch WordNet Wordnet Similarity Demo Wordnet Graphs Cornetto Ambiguity demo Uncertainty Visualization The VU Sound Corpus Soundtags Wsd4Kids Software Ontotagger Kybot KafSaxParser MultiwordTagger KafNafAnnotator EventCoreference WordnetTools Computer Facilities News KAF Home Computational Lexicology & Terminology Lab The Computational Lexicology and Terminology Lab (CLTL) with Prof.Dr. Piek Vossen as director is part of the Department of Language, Literature and Communication of the Faculty of Humanities of the Vrije Universiteit Amsterdam, and of the Network Institute. The Computational Lexicology & Terminology Lab (CLTL) models the understanding of natural language through computers with a central role for knowledge sources such as lexicons, ontologies and terminology. Our application perspective is text mining: technology that is used to automatically extract knowledge and information from text. This ranges from simple statements and fact, to events, storylines, to opinions and world-views. Within this main research goal, we study and model the lexicon in all its facets. We consider the lexicon as a neural-cognitive product including epistemic and symbolic features. From this perspective, our research question is “how these neural-cognitive systems develop and function when we learn and use language?”. We also consider lexicons as a module for many computer applications that are knowledge-based. We are especially interested in the role of the lexicon as a bridge between form and meaning. Our research question here is: “how can we anchor words and expressions to formalized meaning so that computers can simulate language understanding and effective communication?”. A third research question relates to the acquisition of lexical knowledge from text-corpora, specifically terminology in specialized communities and context. What words are used, how they relate semantically, what their distribution is, how they collocate. We develop automatic techniques and methods to answer these questions.  Finally: we do all lexical and terminological research for multiple languages. An important project is the building of the Global Wordnet Grid: this project aims at representing many vocabularies of languages as semantic networks or wordnets and combining them through a universal index of meaning. Building and studying this grid will tell us more about universalities and idiosyncrasies of languages and likewise about the roles and functions of words and expressions. Video explaining  5 years of research in the Spinoza-projects “Understanding Language by Machines“, 2019 Video explaining NewsReader‘s Reading Machine — Example of one of CLTL’s projects Lecture (in Dutch) Prof. dr. Piek Vossen at Paradiso Amsterdam: ‘To Communicate with an Imperfect Robot — Get It?’ March 25, 2018 Proudly powered by WordPress \n"
     ]
    }
   ],
   "source": [
    "url =\"http://cltl.nl\"\n",
    "cltl_content=url_to_string(url)\n",
    "print(cltl_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
