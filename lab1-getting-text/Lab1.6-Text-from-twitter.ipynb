{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1.3: Twitter as a source of text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to query Twitter streams using the package **tweepy**: https://github.com/tweepy/tweepy\n",
    "Some documentation can be found at: https://github.com/tweepy/tweepy/tree/master/docs\n",
    "\n",
    "Tweepy allows you to access Twitter using credentials and returns a so-called Cursor object. From the Cursor object, you can access the twitter data in e.g. JSON format. Documentation on the Twitter data objects can be found here:\n",
    "\n",
    "https://developer.twitter.com/en/docs\n",
    "\n",
    "\n",
    "Instructions on how to install Tweepy, get credentials and use the API can be found here:\n",
    "\n",
    "http://socialmedia-class.org/twittertutorial.html\n",
    "\n",
    "The notebook below is partially based on this tutorial. Credits: Wei Xu\n",
    "\n",
    "Make sure you installed the package and obtained the Twitter credentials before your start using the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next code, we are importing a json package and the tweepy package. Next, we first set up tweepy with the authenticaton credentials so that we can make a connection. Consult the documentation how to get yoru credentials. Using the credentials, we call the tweepy.API function to create an api object.\n",
    "\n",
    "We show how you can get the results through a Cursor function of tweepy, in which you need to set a number of variables. We use the search api to pass a keyword as a query and limit the results to a number of tweets, number of pages, excluding retweets and setting a period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\n",
      "User:freedomgirl2011 \n",
      " Tweet:Corporations will make money off your brain damaged child,one in 38 children in United States are diagnosed with… https://t.co/ZT0JOjqTF2\n",
      "\n",
      "1\n",
      "User:andrewmorrisuk \n",
      " Tweet:RT @sallyKP: From 2011... listen.\n",
      "\n",
      "Very sad for all of the families who have been advocating for 20 years now.\n",
      "\n",
      "What would happen if the US…\n",
      "\n",
      "2\n",
      "User:anhisu7 \n",
      " Tweet:RT @sallyKP: From 2011... listen.\n",
      "\n",
      "Very sad for all of the families who have been advocating for 20 years now.\n",
      "\n",
      "What would happen if the US…\n",
      "\n",
      "3\n",
      "User:WarriorWifeMom \n",
      " Tweet:RT @sallyKP: From 2011... listen.\n",
      "\n",
      "Very sad for all of the families who have been advocating for 20 years now.\n",
      "\n",
      "What would happen if the US…\n",
      "\n",
      "6\n",
      "User:andrewmorrisuk \n",
      " Tweet:RT @BioscienceNB: #educateyourself\n",
      "10 years and over 600,000 children.\n",
      "\n",
      "As promised, here is another link to the most recent study conducte…\n",
      "\n",
      "7\n",
      "User:BioscienceNB \n",
      " Tweet:#educateyourself\n",
      "10 years and over 600,000 children.\n",
      "\n",
      "As promised, here is another link to the most recent study co… https://t.co/Vkc5EWVnyy\n",
      "\n",
      "8\n",
      "User:JMONEILL1975 \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "9\n",
      "User:tow4u44 \n",
      " Tweet:RT @and_kell: Do you know vaccines do indeed trigger an encephalopathy in vulnerable children. Later diagnosed as #autism\n",
      "\n",
      "Doctors who push…\n",
      "\n",
      "0\n",
      "User:lizz_dawn \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "1\n",
      "User:JONJONLIVES1 \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "2\n",
      "User:constantin_t \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "3\n",
      "User:LDSLibertarian1 \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "4\n",
      "User:mal0406 \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "5\n",
      "User:bobglomorrison \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "6\n",
      "User:shekinah1313 \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "7\n",
      "User:DrKND \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "8\n",
      "User:littlorangefish \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "9\n",
      "User:terriblewis1 \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "0\n",
      "User:BoggyLuuuu \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "1\n",
      "User:andrewmorrisuk \n",
      " Tweet:RT @and_kell: Do you know vaccines do indeed trigger an encephalopathy in vulnerable children. Later diagnosed as #autism\n",
      "\n",
      "Doctors who push…\n",
      "\n",
      "2\n",
      "User:LORIWIN1 \n",
      " Tweet:RT @and_kell: Do you know vaccines do indeed trigger an encephalopathy in vulnerable children. Later diagnosed as #autism\n",
      "\n",
      "Doctors who push…\n",
      "\n",
      "3\n",
      "User:MinnReb \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "4\n",
      "User:MazymMary \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "5\n",
      "User:DaniForPeace1 \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "6\n",
      "User:UsernameNAB \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "7\n",
      "User:twietsnest \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "8\n",
      "User:andrewmorrisuk \n",
      " Tweet:RT @and_kell: Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mocking &amp; la…\n",
      "\n",
      "9\n",
      "User:and_kell \n",
      " Tweet:Why has nothing changed in 20 ys? Why are pediatricians doing such a poor job with #autism? They sit on @Twitter mo… https://t.co/U9g9gTdD15\n",
      "\n",
      "0\n",
      "User:and_kell \n",
      " Tweet:RT @and_kell: Do you know vaccines do indeed trigger an encephalopathy in vulnerable children. Later diagnosed as #autism\n",
      "\n",
      "Doctors who push…\n",
      "\n",
      "1\n",
      "User:hackedneckbone \n",
      " Tweet:RT @ViraBurnayeva: For the sake of our children, we all should watch &amp; have our relatives to watch #VAXXED:\n",
      "https://t.co/nd0vG6bfH6\n",
      "\n",
      "Cognit…\n",
      "\n",
      "2\n",
      "User:TinaLStephenson \n",
      " Tweet:RT @ViraBurnayeva: For the sake of our children, we all should watch &amp; have our relatives to watch #VAXXED:\n",
      "https://t.co/nd0vG6bfH6\n",
      "\n",
      "Cognit…\n",
      "\n",
      "3\n",
      "User:MaryAgu10062001 \n",
      " Tweet:RT @ViraBurnayeva: For the sake of our children, we all should watch &amp; have our relatives to watch #VAXXED:\n",
      "https://t.co/nd0vG6bfH6\n",
      "\n",
      "Cognit…\n",
      "\n",
      "4\n",
      "User:ViraBurnayeva \n",
      " Tweet:RT @ViraBurnayeva: For the sake of our children, we all should watch &amp; have our relatives to watch #VAXXED:\n",
      "https://t.co/nd0vG6bfH6\n",
      "\n",
      "Cognit…\n",
      "\n",
      "5\n",
      "User:grhluna24 \n",
      " Tweet:RT @UVMPattyPrelock: First day in #Hangzhou #China speaking to students and colleagues at the Traditional Chinese Medicine University  as t…\n",
      "\n",
      "6\n",
      "User:UVMPattyPrelock \n",
      " Tweet:First day in #Hangzhou #China speaking to students and colleagues at the Traditional Chinese Medicine University  a… https://t.co/LIAcYTQHBz\n",
      "\n",
      "7\n",
      "User:DianeRo64727777 \n",
      " Tweet:RT @ViraBurnayeva: For the sake of our children, we all should watch &amp; have our relatives to watch #VAXXED:\n",
      "https://t.co/nd0vG6bfH6\n",
      "\n",
      "Cognit…\n",
      "\n",
      "8\n",
      "User:patriot7842 \n",
      " Tweet:RT @ViraBurnayeva: For the sake of our children, we all should watch &amp; have our relatives to watch #VAXXED:\n",
      "https://t.co/nd0vG6bfH6\n",
      "\n",
      "Cognit…\n",
      "\n",
      "9\n",
      "User:Villianelle2 \n",
      " Tweet:RT @ViraBurnayeva: For the sake of our children, we all should watch &amp; have our relatives to watch #VAXXED:\n",
      "https://t.co/nd0vG6bfH6\n",
      "\n",
      "Cognit…\n",
      "\n",
      "0\n",
      "User:scottfreeanon \n",
      " Tweet:RT @ViraBurnayeva: For the sake of our children, we all should watch &amp; have our relatives to watch #VAXXED:\n",
      "https://t.co/nd0vG6bfH6\n",
      "\n",
      "Cognit…\n",
      "\n",
      "1\n",
      "User:DrJulissa \n",
      " Tweet:CHILDHOOD VACCINES ARE A PART OF THE #AUTISM DEBATE. Some parents say the multiple, wide-ranging vaccines now given… https://t.co/UQYrwU9Xxi\n",
      "\n",
      "2\n",
      "User:RabbieGuevara \n",
      " Tweet:RT @ViraBurnayeva: For the sake of our children, we all should watch &amp; have our relatives to watch #VAXXED:\n",
      "https://t.co/nd0vG6bfH6\n",
      "\n",
      "Cognit…\n",
      "\n",
      "3\n",
      "User:FlatplaneJayne \n",
      " Tweet:RT @ViraBurnayeva: For the sake of our children, we all should watch &amp; have our relatives to watch #VAXXED:\n",
      "https://t.co/nd0vG6bfH6\n",
      "\n",
      "Cognit…\n",
      "\n",
      "4\n",
      "User:PJMoore1958 \n",
      " Tweet:RT @ViraBurnayeva: For the sake of our children, we all should watch &amp; have our relatives to watch #VAXXED:\n",
      "https://t.co/nd0vG6bfH6\n",
      "\n",
      "Cognit…\n",
      "\n",
      "5\n",
      "User:fannabanana \n",
      " Tweet:RT @ViraBurnayeva: For the sake of our children, we all should watch &amp; have our relatives to watch #VAXXED:\n",
      "https://t.co/nd0vG6bfH6\n",
      "\n",
      "Cognit…\n",
      "\n",
      "6\n",
      "User:Awnye4 \n",
      " Tweet:RT @ViraBurnayeva: For the sake of our children, we all should watch &amp; have our relatives to watch #VAXXED:\n",
      "https://t.co/nd0vG6bfH6\n",
      "\n",
      "Cognit…\n",
      "\n",
      "7\n",
      "User:sccstarkell \n",
      " Tweet:RT @ViraBurnayeva: For the sake of our children, we all should watch &amp; have our relatives to watch #VAXXED:\n",
      "https://t.co/nd0vG6bfH6\n",
      "\n",
      "Cognit…\n",
      "\n",
      "8\n",
      "User:jackaranian \n",
      " Tweet:RT @ViraBurnayeva: For the sake of our children, we all should watch &amp; have our relatives to watch #VAXXED:\n",
      "https://t.co/nd0vG6bfH6\n",
      "\n",
      "Cognit…\n",
      "\n",
      "9\n",
      "User:QNuevomedio \n",
      " Tweet:RT @ViraBurnayeva: For the sake of our children, we all should watch &amp; have our relatives to watch #VAXXED:\n",
      "https://t.co/nd0vG6bfH6\n",
      "\n",
      "Cognit…\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary package to process data in JSON format\n",
    "try:\n",
    "    import json\n",
    "except ImportError:\n",
    "    import simplejson as json\n",
    "\n",
    "# Import the tweepy library\n",
    "import tweepy\n",
    "\n",
    "# Variables that contains the user credentials to access Twitter API \n",
    "#ACCESS_TOKEN = 'YOUR ACCESS TOKEN\"'\n",
    "#ACCESS_SECRET = 'YOUR ACCESS TOKEN SECRET'\n",
    "#CONSUMER_KEY = 'YOUR API KEY'\n",
    "#CONSUMER_SECRET = 'ENTER YOUR API SECRET'\n",
    "\n",
    "# Variables that contains the user credentials to access Twitter API \n",
    "ACCESS_TOKEN = ''\n",
    "ACCESS_SECRET = ''\n",
    "CONSUMER_KEY = ''\n",
    "CONSUMER_SECRET = ''\n",
    "\n",
    "# Setup tweepy to authenticate with Twitter credentials:\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "# Create the api to connect to twitter with your credentials\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True)\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# wait_on_rate_limit= True;  will make the api to automatically wait for rate limits to replenish\n",
    "# wait_on_rate_limit_notify= Ture;  will make the api  to print a notification when Tweepyis waiting for rate limits to replenish\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# we now predefine some variables to restrict the twitter stream\n",
    "\n",
    "#set two date variables for date range\n",
    "start_date = '2018-10-01'\n",
    "end_date = '2018-10-31'\n",
    "\n",
    "#we define the nr_tweets we want to return \n",
    "nr_tweets=10\n",
    "\n",
    "#finally, we define a query. Note that we can mix hash tags with words and use boolean operators OR and AND\n",
    "keywords='#autism AND vaccines OR medicine AND children'\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "# Twitter API development use pagination for Iterating through timelines, user lists, direct messages, etc. \n",
    "# To help make pagination easier and Tweepy has the Cursor object.\n",
    "#---------------------------------------------------------------------------------------------------------------------\n",
    "for page in tweepy.Cursor(api.search, q=keywords,\n",
    "                     count=nr_tweets, include_rts=False, since=start_date, till=end_date).pages(5):\n",
    "    for index, status in enumerate(page):\n",
    "        \n",
    "        ## we get a json object from the result\n",
    "        json_result = status._json\n",
    "        \n",
    "        ## check whether the tweet is in english or skip to the next tweet\n",
    "        if json_result['lang'] != 'en':\n",
    "            continue\n",
    "\n",
    "        text=json_result['text']\n",
    "        name=json_result['user']['screen_name']\n",
    "        print(\"\\n\"+str(index)+\"\\nUser:\"+name, \"\\n\", \"Tweet:\" + text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here 5 pages which each 10 tweets, where we print the user name and the text. As you can see, the tweets contains all kinds of non-textual elements as well.\n",
    "\n",
    "Instead of printing the tweet text and screen name to the screen, we also directly dump the JSON result to a file.\n",
    "We show this next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a file path to store the results as CSV. Make sure the folder 'twitter_search_results' exists \n",
    "# or that you specify another path to an existing location. The 'twitter_results_vaccination.csv' file will be created in that location.\n",
    "jsonFilePath='twitter_search_results/twitter_results_vaccination.json'\n",
    "\n",
    "\n",
    "for page in tweepy.Cursor(api.search, q=keywords,\n",
    "                     count=nr_tweets, include_rts=False, since=start_date, till=end_date).pages(5):\n",
    "    for index, status in enumerate(page):\n",
    "        \n",
    "        ## we get a json object from the result\n",
    "        json_result = status._json\n",
    "        ## we open the result file for appending the JSON\n",
    "        jsonFile = open(jsonFilePath, 'a' ,encoding='utf-8')\n",
    "        ## To save the data, we need to convert it to a 'str'\n",
    "        jsonFile.write(str(json_result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now open the file *jsonFilePath* in a plain text editor and inspect the structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The JSON output contains all kinds of meta data in addition to the tweet ietself. We are going to show how you can get these and save the result as a CSV output file. We assume the above imports and credentials and re-use the api we defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain the relevant information, you need to know the JSON structure of the output. Please consult the Twitter documentation to understand the structure.\n",
    "\n",
    "https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/intro-to-tweet-json\n",
    "\n",
    "We are going to define a number of columns for a CSV file to store the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS = ['id', 'created_at', 'source', 'tweet_text', 'lang',\n",
    "'favorite_count', 'retweet_count', 'original_author', 'hashtags',\n",
    "'user_mentions', 'place', 'place_coord_boundaries']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code shows how we obtain the above data from the JSON structure and store it in a single CSV file. For illustration, we are going to use the same settings and API as before.\n",
    "\n",
    "To create the output as CSV data, we are going to use the Pandas package: https://pandas.pydata.org\n",
    "Please follow the instructions to install pandas locally:\n",
    "\n",
    "* conda install pandas\n",
    "* python -m pip install --upgrade pandas\n",
    "\n",
    "Consult the documentation to learn more about the functionalities. Here we are going to use it to convert our list of featurures for a tweet to a CSV format.\n",
    "\n",
    "We need to import *os* for writing to a file and *pandas* (after the install) for dealing with the data structure. Take your time to study the next bit of code so that you understand the individual steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#set two date variables for date range\n",
    "start_date = '2018-10-01'\n",
    "end_date = '2018-10-31'\n",
    "\n",
    "#we define the nr_tweets we want to return \n",
    "nr_tweets=10\n",
    "\n",
    "#finally, we define a query. Note that we can mix hash tags with words and use boolean operators OR and AND\n",
    "keywords='#autism AND vaccines OR medicine AND children'\n",
    "\n",
    "# We first define a data frame that we name 'all_tweets_dataframe' with pandas imported as 'pd' using the columns list that we defined before.\n",
    "# Basically, we tell pandas what data will be stored.\n",
    "all_tweets_dataframe = pd.DataFrame(columns=COLS)\n",
    "\n",
    "for page in tweepy.Cursor(api.search, q=keyword,\n",
    "                     count=nr_tweets, include_rts=False, since=start_date).pages(50):\n",
    "    # now we have the tweets, we are going to obtain the features from the json and store them in the right order for our data frame\n",
    "    for status in page:\n",
    "        ## new_entry is going to contain the data \n",
    "        new_entry = []\n",
    "        \n",
    "        ## we get a json object from the result\n",
    "        status = status._json\n",
    "        \n",
    "        ## check whether the tweet is in english or skip to the next tweet\n",
    "        if status['lang'] != 'en':\n",
    "            continue\n",
    "\n",
    "        text=status['text']\n",
    "        \n",
    "        #new entry append in the order of the data frame\n",
    "        new_entry += [status['id'], \n",
    "                      status['created_at'],\n",
    "                      status['source'], \n",
    "                      status['text'],\n",
    "                      status['lang'],\n",
    "                      status['favorite_count'], \n",
    "                      status['retweet_count']]\n",
    "\n",
    "        #to append original author of the tweet\n",
    "        new_entry.append(status['user']['screen_name'])\n",
    "\n",
    "        # hashtagas and mentiones are saved using comma separted\n",
    "        hashtags = \", \".join([hashtag_item['text'] for hashtag_item in status['entities']['hashtags']])\n",
    "        new_entry.append(hashtags)\n",
    "        mentions = \", \".join([mention['screen_name'] for mention in status['entities']['user_mentions']])\n",
    "        new_entry.append(mentions)\n",
    "\n",
    "        #get location of the tweet if possible\n",
    "        try:\n",
    "            location = status['user']['location']\n",
    "        except TypeError:\n",
    "            location = ''\n",
    "        new_entry.append(location)\n",
    "\n",
    "        try:\n",
    "            coordinates = [coord for loc in status['place']['bounding_box']['coordinates'] for coord in loc]\n",
    "        except TypeError:\n",
    "            coordinates = None\n",
    "        new_entry.append(coordinates)\n",
    "\n",
    "        # We now completed appending all the possible values for this tweet.\n",
    "        # We use the pandas framework imported as 'pd' to create a dataframe from the aggregated data in new_entry\n",
    "        # We need to provide the columns COLS to tell pandas what value belongs to what.\n",
    "        # Note that the data need to be aggregated in the same order as the names in COLS, otherwise values will get mixed up\n",
    "        single_tweet_dataframe = pd.DataFrame([new_entry], columns=COLS)\n",
    "        \n",
    "        # single_tweet_dataframe now contains the data for a single tweet\n",
    "        # next we add it to the data frame for all tweets 'all_tweets_dataframe'\n",
    "        # check the pandas documentation if you want to know what ignore_index=True does to the data aggregation\n",
    "        all_tweets_dataframe = all_tweets_dataframe.append(single_tweet_dataframe, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data frame basically is a table with columns and rows. We use the *shape* function to ask for the number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 12)\n"
     ]
    }
   ],
   "source": [
    "print(all_tweets_dataframe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the *pandas* framework, we can now save it to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a file path to store the results as CSV. Make sure the folder 'twitter_search_results' exists \n",
    "# or that you specify another path to an existing location. The 'twitter_results_vaccination.csv' file will be created in that location.\n",
    "csvFilePath='twitter_search_results/twitter_results_vaccination.csv'\n",
    "\n",
    "# we now open the csvFile for appending our result\n",
    "csvFile = open(csvFilePath,\"w+\")       \n",
    "all_tweets_dataframe.to_csv(csvFile, columns=COLS, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
