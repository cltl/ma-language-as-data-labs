{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab5.3 - Sentiment analysis using VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright, Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we introduce how to use [VADER](https://github.com/cjhutto/vaderSentiment) as part of the NLTK to perform sentiment analysis.\n",
    "\n",
    "**at the end of this notebook, you will**:\n",
    "* have VADER installed on your computer\n",
    "* be able to load the VADER model\n",
    "* be able to apply the VADER model on new sentences:\n",
    "    * with and without lemmatization\n",
    "    * with only providing VADER with certain parts of speech, e.g., only providing the adjectives from a sentences as input to VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The VADER package in NLTK\n",
    "Please run the following commands first to download VADER to your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using VADER for the first time, you need to install it within NLTK. If you have done this before you can comment out the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/piek/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon', quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify that the download was successful, you can run the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import vader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER is rule-based system that makes use of a lexicon. The lexicon can be found [here](https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vader_lexicon.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can be loaded in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_model = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following three sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"Here are my sentences.\",\n",
    "             \"It's a nice day.\",\n",
    "             \"It's a rainy day.\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next for loop assigns a sentiment score from VADER to **each sentence**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INPUT SENTENCE Here are my sentences.\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.714, 'pos': 0.286, 'compound': 0.0516}\n",
      "\n",
      "INPUT SENTENCE It's a nice day.\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'compound': 0.4215}\n",
      "\n",
      "INPUT SENTENCE It's a rainy day.\n",
      "VADER OUTPUT {'neg': 0.394, 'neu': 0.606, 'pos': 0.0, 'compound': -0.0772}\n"
     ]
    }
   ],
   "source": [
    "for sent in sentences:\n",
    "    scores = vader_model.polarity_scores(sent)\n",
    "    print()\n",
    "    print('INPUT SENTENCE', sent)\n",
    "    print('VADER OUTPUT', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Combining VADER with spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can manipulate the input to VADER by providing the lemmas as input instead of the words and by only providing words with certain parts of speech, e.g., only adjectives. We use spaCy for the lemmatization and part of speech tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en') # en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function takes text, processes it using spaCy and applies VADER according to different settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a custom-made function that expects text as input:\n",
    "#\n",
    "#1) runs SpaCy on the text, \n",
    "#2) prepares the SpaCy sentences for VADER\n",
    "#3) runs VADER on each sentence\n",
    "#Finally returns the aggregated scores\n",
    "\n",
    "def run_vader(textual_unit, \n",
    "              lemmatize=False, \n",
    "              parts_of_speech_to_consider=set(),\n",
    "              verbose=0):\n",
    "    \"\"\"\n",
    "    Run VADER on a sentence from spacy\n",
    "    \n",
    "    :param str textual unit: a textual unit, e.g., sentence, sentences (one string)\n",
    "    (by looping over doc.sents)\n",
    "    :param bool lemmatize: If True, provide lemmas to VADER instead of words\n",
    "    :param set parts_of_speech_to_consider:\n",
    "    -empty set -> all parts of speech are provided\n",
    "    -non-empty set: only these parts of speech are considered\n",
    "    :param int verbose: if set to 1, information is printed\n",
    "    about input and output\n",
    "    \n",
    "    :rtype: dict\n",
    "    :return: vader output dict\n",
    "    \"\"\"\n",
    "    doc = nlp(textual_unit)\n",
    "        \n",
    "    input_to_vader = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "\n",
    "            to_add = token.text\n",
    "\n",
    "            if lemmatize:\n",
    "                to_add = token.lemma_\n",
    "\n",
    "                if to_add == '-PRON-': \n",
    "                    to_add = token.text\n",
    "\n",
    "            if parts_of_speech_to_consider:\n",
    "                if token.pos_ in parts_of_speech_to_consider:\n",
    "                    input_to_vader.append(to_add) \n",
    "            else:\n",
    "                input_to_vader.append(to_add)\n",
    "\n",
    "    scores = vader_model.polarity_scores(' '.join(input_to_vader))\n",
    "    \n",
    "    if verbose >= 1:\n",
    "        print()\n",
    "        print('INPUT SENTENCE', sent)\n",
    "        print('INPUT TO VADER', input_to_vader)\n",
    "        print('VADER OUTPUT', scores)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide VADER with lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"Here are my sentences.\",\n",
    "             \"It's a nice day.\",\n",
    "             \"It's a rainy day.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.517, 'pos': 0.483, 'compound': 0.4215}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_vader(sentences[1], lemmatize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you want the function to print more information, you can set the keyword argument **verbose** to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INPUT SENTENCE It's a nice day.\n",
      "INPUT TO VADER ['It', 'be', 'a', 'nice', 'day', '.']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.517, 'pos': 0.483, 'compound': 0.4215}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.517, 'pos': 0.483, 'compound': 0.4215}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running the function on a single sentence\n",
    "run_vader(sentences[1], lemmatize=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also filter on part of speech. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only Nouns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INPUT SENTENCE It's a nice day.\n",
      "INPUT TO VADER ['day']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_vader(sentences[1], \n",
    "          lemmatize=True, \n",
    "          parts_of_speech_to_consider={'NOUN'},\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only verbs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INPUT SENTENCE It's a nice day.\n",
      "INPUT TO VADER ['be']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_vader(sentences[1], \n",
    "          lemmatize=True, \n",
    "          parts_of_speech_to_consider={'VERB'},\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INPUT SENTENCE It's a nice day.\n",
      "INPUT TO VADER ['nice']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_vader(sentences[1], \n",
    "          lemmatize=True, \n",
    "          parts_of_speech_to_consider={'ADJ'},\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Applying VADER to attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "attributions=()\n",
    "with open('attribution-relations.pickle', 'rb') as inputfile:\n",
    "    attributions=pickle.load(inputfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('make', ' Amazon', 'ORG', ' this week just grocery delivery free , so Walmart is now touting how its grocery service offers the booze .')\n",
      "('raise', ' Earl Mobile banking app Current', 'PERSON', ' $ 20 M Series B , tops half a million users')\n",
      "('roll', ' Google', 'ORG', ' Sarah Perez A year ago , out “ .new')\n",
      "('follow', ' Google Play Pass', 'ORG', ' soon as a way to subscribe to a sizable collection of both apps and ga Spotify now lets artists buy a full - screen ‘ recommendation ’ promoting their new album Oct 24 , 2019')\n",
      "('work', ' Sarah', 'PERSON', ' Prior to her work as a reporter , in I.T. across a number of industries , including banking , retail and software .')\n",
      "('rise', ' Sarah Perez North Carolina', 'PERSON', ' has been as an entrepreneurial hub .')\n",
      "('add', ' Sarah Perez Spotify', 'PERSON', ' recently a feature that will occasionally pop up a full - screen recommendation of a new album the service thinks you ’ll like , based on a combination of your listening taste and huma Apple TV app comes to Amazon ’s Fire TV Stick and other devices Oct 24 , 2019')\n",
      "('announce', ' Sarah Perez Walmart', 'PERSON', ' today an expansion of its existing relationship with financial services provider Green Dot , which will continue to serve as the issuing bank and program manager for the Walmart Money Sony to shut down PlayStation Vue on January 30 , 2020 Oct 29 , 2019 Sarah Perez Sony ’s live TV streaming service , PlayStation Vue , is shutting down .')\n",
      "('work', ' Sarah Perez Writer Sarah', 'PERSON', ' currently as a writer for TechCrunch , after having previously spent over three years at ReadWriteWeb .')\n",
      "('announce', ' Spotify', 'PERSON', ' In a move to boost family subscriptions to its app , this morning the launch of a dedicated Kids application which allows children three and up to listen to their own music , both onli HBO Max will cost $ 14.99 per month and launch in May 2020')\n",
      "('tout', ' Walmart', 'PERSON', ' is now how its grocery service offers the booze .')\n",
      "('come', ' huma Apple TV app', 'ORG', ' to Amazon ’s Fire TV Stick and other devices Oct 24 , 2019')\n"
     ]
    }
   ],
   "source": [
    "for attribution in attributions:\n",
    "    print(attribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take the predicate and the content and apply VADER to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n"
     ]
    }
   ],
   "source": [
    "for attribution in attributions:\n",
    "    text = attribution[0]+attribution[3]\n",
    "    sentiment = run_vader(sentences[1], \n",
    "          lemmatize=True, \n",
    "          parts_of_speech_to_consider={'ADJ'},\n",
    "          verbose=0)\n",
    "    print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.517, 'pos': 0.483, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.517, 'pos': 0.483, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.517, 'pos': 0.483, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.517, 'pos': 0.483, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.517, 'pos': 0.483, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.517, 'pos': 0.483, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.517, 'pos': 0.483, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.517, 'pos': 0.483, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.517, 'pos': 0.483, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.517, 'pos': 0.483, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.517, 'pos': 0.483, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.517, 'pos': 0.483, 'compound': 0.4215}\n"
     ]
    }
   ],
   "source": [
    "for attribution in attributions:\n",
    "    text = attribution[0]+attribution[3]\n",
    "    sentiment = run_vader(sentences[1], \n",
    "          lemmatize=True,\n",
    "          verbose=0)\n",
    "    print(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
